- This data analysis pipeline is adapted from scNT-seq and Well-TEMP-seq, including reads extraction from 10Xgenomics bam file, T-C reads subtraction, T-C background subtraction, reads counting and statistic correction.

- Pre-install requirment: cellranger ( > version 7.0), samtools, sam2tsv, perl, Rscript, python
- Run step 1- 6 on a no-4sU treatment, no-conversion sample to generate a background T-C mutation pattern which will be used in step 8.

0. cellranger workflow

```shell
# use a dummy data (sample) for demonstration

0.1 retrieve fastq file 
# download sequencing data from the sequencing service provider
wget "http://cleversafetest.nci.nih.gov/SEQ37V/NEXTSEQ2000/221218_VH00687_137_AAATWNFHV.tar?Signature=lxwNZ2l%2FdZPuHCmgilQ%2BtTWo%2F9I%3D&Expires=1672650742&AWSAccessKeyId=l6JcnKaAlMCbhfDQpECs" -O 221218_VH00687_137_AAATWNFHV_Data.tar

# Untar files in Current Directory ##
tar -xvf 221218_VH00687_137_AAATWNFHV_Data.tar

x - extract.
v – Verbosely show the .tar file progress.
f – File name type of the archive file.

# prepare sample sheet
1, download the simple samplesheet from 10X or use IEM samplesheet.
2, change the index information
For example, with the Dual Index Kit TT Set A, well A1 can be specified in the sample sheet as "SI-TT-A1", and cellranger mkfastq will recognize the i7 and i5 indices as GTAACATGCG and AGTGTTACCT, respectively. Similarly for Single Index Kit T Set A, well A1 can be specified in the sample sheet as "SI-GA-A1", and cellranger mkfastq will recognize the four i7 indexes (GGTTTACT, CTAAACGG, TCGGCGTC, and AACCGTAA) and merge the resulting FASTQ files.
3, specify the lane. It can be either a single lane, a range (e.g., 2-4) or "*" for all lanes in the flow cell.

# run mkfastq
cellranger mkfastq --id=samplefq \
                     --run=221218_VH00687_137_AAATWNFHV \
                     --csv=cellranger-tiny-bcl-simple-1.2.0.csv \
                     --localcores=$SLURM_CPUS_PER_TASK \
                     --localmem=120

# The two parameters below are set for a biowulf setting
--localcores=$SLURM_CPUS_PER_TASK 
--localmem=120

There are three arguments or inputs that are added to the cellranger mkfastq command: –-id, --run, and --csv.

The --id can be anything. It is used by the pipeline to name the output directory that Cell Ranger is going to create to run in. This directory is called a pipestance, which is short for pipeline instance.

The --run argument points to the Illumina run folder that contains the BCL files.

The --csv argument is a comma-separated value (CSV) file that describes how samples were indexed on the Illumina flow cell.

0.2 count UMI
1, There are several prebuilt human reference transcriptome packages on the 10x Genomics support site. Download the latest package and decompress it. however, this step is not necessary on biowulf.

# download reference (optional)
wget https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz
tar -zxvf refdata-gex-GRCh38-2020-A.tar.gz

cellranger count --id=count_eHAP1 \
   --fastqs=sample \
   --sample=sample \
   --transcriptome=$CELLRANGER_REF/refdata-gex-GRCh38-2020-A \
   --localcores=$SLURM_CPUS_PER_TASK \
   --localmem=120

# This step takes some time. I use the swarm command on biowulf.

# command annotations     
   --id Cell Ranger creates an output directory that is named using this id. 
   --fastqs should be a path to the directory containing the FASTQ files
   --sample argument to specify which samples to use, If there is more than one sample in the FASTQ directory
   --transcriptome reference package
```

1. Prepare a tag-containing cellular barcode (CB) list and a tag-removing CB list for reads extraction  

```R
# use a dummy data (sample) for demonstration in R
# QC and barcode extraction
sample.data <-  Read10X(data.dir = "./filtered_feature_bc_matrix/")
sample <- CreateSeuratObject(counts = sample.data, project = "NOTEseq", min.cells = 3, min.features = 200)
sample <- PercentageFeatureSet(sample, "^MT-", col.name = "percent_mito")

# subset cells based on your criteria 
sample.filter <- subset(sample, nCount_RNA > 5000 & nCount_RNA < 50000 & percent_mito < 5)

# retrieve cellular barcodes 
barcode_subset <- colnames(sample.filter)
write.table(barcode_subset,file = 'sample_barcode_st_subset.txt',sep = '\t',row.names = F,col.names = F,quote = F) # this will be used in the statistic correction step.
barcode_subset <- paste0('CB:Z:',barcode_subset)
write.table(barcode_subset,file = 'sample_barcode_subset.txt',sep = '\t',row.names = F,col.names = F,quote = F) # this will be used in the initial bam subtraction step. 
```

2. Extract reads from bam file generated by cellranger.

```shell
# retrieve reads using barcode list. use LC_ALL=C to set C locale instead of UTF-8
samtools view possorted_genome_bam.bam | LC_ALL=C grep -F -f sample_barcode_subset.txt > filtered_SAM_body.sam

# select reads confidently mapped to genome and contributing to the UMI counting.
cat filtered_SAM_body.sam | LC_ALL=C grep "xf:i:25" > body_filtered_sam

# Extract the BAM header and write to header_filted_sam
samtools view -H possorted_genome_bam.bam > header_filtered_sam 

# Combine the header and extracted records
cat header_filtered_sam body_filtered_sam > sample_filtered.sam

# convert sam to bam for a later step
samtools view -b sample_filtered.sam > sample_possorted_genome_bam_filtered.bam
```

3. Extract read ID with GX:Z annotation (get read with gene ID )

```shell
# the xf:i:25 tag before already takes care of the annotated reads, and thus grep "GX:Z" is optional.
grep "GX:Z" sample_filtered.sam | awk '{print $1}' > sample_filtered_ann_read.txt
```

4. Convert SAM format to TSV by Sam2Tsv

```shell
4.1 generate ref with 'samtools faidx' and 'picard CreateSequenceDictionary'
# we use the genome.fa from cellranger reference
module load cellranger
the genome.fa is used by cellranger
$CELLRANGER_REF/refdata-gex-GRCh38-2020-A/fasta/genome.fa

# cp genome.fa to sam2tsv directory, and cd to sam2tsv directory
# build index with samtools faidx
samtools faidx genome.fa

# build index with picard CreateSequenceDictionary
module load picard
java -Xmx4g -XX:ParallelGCThreads=25 -jar $PICARDJARPATH/picard.jar CreateSequenceDictionary -R genome.fa

4.2 run Sam2Tsv 
#Sam2Tsv is part of jvarkit, so we load jvarkit on biowulf.
module load jvarkit 
# run sam2tsv
java -jar $JVARKIT_JARPATH/sam2tsv.jar --reference /data/lyuj2/sam2tsv_ref/genome.fa sample_filtered.sam | awk '{if ($10 ~/M|=|X/) print $0}'  > sample_both_strand_all.tsv
```

5.  Extract T->C mutation from _all.tsv considering both strands

```shell
awk '{if ($2 ==0 && $6=="C" && $9=="T") print $0; else if ( $2==16 && $6=="G" && $9=="A" ) print $0}' sample_both_strand_all.tsv > sample_both_strand_all_TC.tsv
```

6. Retain T-to-C substitutions with a base Phred quality score of > 27

```shell
perl /data/lyuj2/TC_calling_adaptedfor10X/scripts/extrac_refT_readC.pl -tsv sample_both_strand_all_TC.tsv -qual 27
```

7. QC output: summarise the all types of mutation rate

```shell
perl /data/lyuj2/TC_calling_adaptedfor10X/scripts/extrac_conversion_frequency_gene_annotate.pl -read sample_filterd_ann_read.txt -tsv sample_both_strand_all.tsv -qual 27
```

8. Background deduction

```shell
perl /data/lyuj2/TC_calling_adaptedfor10X/scripts/background_correction.pl -bg BG_both_strand_all_TC.tsv_q27.tsv -in sample_both_strand_all_TC.tsv_q27.tsv
```

9. Add mutation information back to bam files. 

```shell
# I have changed the tag (replace GE:Z with GN:Z) in the script
perl  /data/lyuj2/TC_calling_adaptedfor10X/scripts/TagIntronicRead_V5.pl -read sample_both_strand_all_TC.tsv_q27.tsv_corrected.tsv -bam sample_possorted_genome_bam_filtered.bam
```

10. Extract the intermediate file

```shell
perl /data/lyuj2/TC_calling_adaptedfor10X/scripts/extract_digital_expression_matrix.pl sample_possorted_genome_bam_filtered.TagTC.corrected.bam
```

11. Generate T->C matrix with rds format

```shell
# I modified the R script, so only 2 parameters are required.
Rscript /data/lyuj2/TC_calling_adaptedfor10X/scripts/Generate_T_C_matrix.R sample_possorted_genome_bam_filtered.TagTC.corrected_gene_cell_UMI_read.txt sample_TC_matrix.rds
```

12. Statistic correction begins with the following steps 

```shell
awk '{if ($10 ~/M|=|X/ && $2==0 && $9=="T") print $0; else if ($10 ~/M|=|X/ && $2==16 && $9=="A") print $0}' sample_both_strand_all.tsv > sample_both_strand_available_site.tsv
```

13. ExtractMappingInfo

```shell
# replace the drop-seq tag with 10X tag,and use the untagged CB list
# get mapping information and write the read name, cell barcode, UMI, and gene name to the output file
python /data/lyuj2/TC_calling_adaptedfor10X/statistical_correction/ExtractMappingInfo.py sample_filtered.sam sample_barcode_st_subset.txt
```

14. statistic correction and output old and new RNA matrixes 

```shell
# because the UMIs have been filtered by 10X and selected by TC calling step, we don't need several filtering steps in the original R scripts. I modified the script to fit our analysis pipeline. This step takes several hours.

# count T number and mutated T number for each UMIs, then generate sample_count.txt
Rscript /data/lyuj2/TC_calling_adaptedfor10X/statistical_correction/Count_bycell_cutoff.R sample
# random sample the first 100K data points for downstream modeling
sort -R sample_count.txt | head -n100000 > sample_sampling.txt
# estimate theta for each cells and correct the labeled transcripts, then output old and new RNA matrixes 
Rscript /data/lyuj2/TC_calling_adaptedfor10X/statistical_correction/likehood_theta_for_gene_100times.R sample
```

